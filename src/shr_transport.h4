dnl vi: set ft=m4
/* -*- C -*-
 *
 * Copyright (c) 2019 Intel Corporation. All rights reserved.
 * This software is available to you under the BSD license.
 *
 * This file is part of the Sandia OpenSHMEM software package. For license
 * information, see the LICENSE file in the top level directory of the
 * distribution.
 *
 */

/*
 * This is a generated file, do not edit directly.
 */

include(shmem_bind_c.m4)dnl

#ifndef SHR_TRANSPORT_H
#define SHR_TRANSPORT_H

#ifdef USE_XPMEM
#include "transport_xpmem.h"
#endif

#ifdef USE_CMA
#include "transport_cma.h"
#endif

#ifdef USE_MMAP
#include "transport_mmap.h"
#endif

static inline int
shmem_shr_transport_init(void)
{
    int ret = 0;

#if USE_XPMEM
    ret = shmem_transport_xpmem_init();
    if (0 != ret)
        RETURN_ERROR_MSG("XPMEM init failed (%d)\n", ret);

#elif USE_CMA
    ret = shmem_transport_cma_init();
    if (0 != ret)
        RETURN_ERROR_MSG("CMA init failed (%d)\n", ret);

#elif USE_MMAP
    ret = shmem_transport_mmap_init();
    if (0 != ret)
        RETURN_ERROR_MSG("mmap init failed (%d)\n", ret);
#endif

    return ret;
}


static inline int
shmem_shr_transport_startup(void)
{
    int ret = 0;

#if USE_XPMEM
    ret = shmem_transport_xpmem_startup();
    if (0 != ret) {
        RETURN_ERROR_MSG("XPMEM startup failed (%d)\n", ret);
    }

#elif USE_CMA
    ret = shmem_transport_cma_startup();
    if (0 != ret) {
        RETURN_ERROR_MSG("CMA startup failed (%d)\n", ret);
    }

#elif USE_MMAP
    ret = shmem_transport_mmap_startup();
    if (0 != ret) {
        RETURN_ERROR_MSG("mmap startup failed (%d)\n", ret);
    }
#endif

    return ret;
}


static inline void
shmem_shr_transport_fini(void)
{
#if USE_XPMEM
    shmem_transport_xpmem_fini();
#elif USE_CMA
    shmem_transport_cma_fini();
#elif USE_MMAP
    shmem_transport_mmap_fini();
#endif
}


/* Return in local_ptr, a local pointer that can be used to access the target
 * buffer for the PE with noderank ID. */
static inline void
shmem_shr_transport_ptr(void *target, int noderank, void **local_ptr)
{
#if USE_XPMEM
    XPMEM_GET_REMOTE_ACCESS(target, noderank, *local_ptr);
#elif USE_MMAP
    MMAP_GET_REMOTE_ACCESS(target, noderank, *local_ptr);
#else
    RAISE_ERROR_MSG("No path to peer (%d)\n", noderank);
#endif
}


static inline int
shmem_shr_transport_use_write(shmem_ctx_t ctx, void *target, const void *source,
                              size_t len, int pe)
{
#if USE_CMA
    return  -1 != shmem_internal_get_shr_rank(pe) &&
           len <= shmem_internal_params.CMA_PUT_MAX;
#else
    return -1 != shmem_internal_get_shr_rank(pe);
#endif
}


static inline int
shmem_shr_transport_use_read(shmem_ctx_t ctx, void *target, const void *source,
                             size_t len, int pe)
{
#if USE_CMA
    return  -1 != shmem_internal_get_shr_rank(pe) &&
           len <= shmem_internal_params.CMA_GET_MAX;
#else
    return -1 != shmem_internal_get_shr_rank(pe);
#endif
}


/* Each OpenSHMEM AMO has only one symmetric pointer.  Check whether shared
 * transport AMOs are in use with respect to the given symmetric target
 * pointer and datatype. For a given datatype, all atomic operations must
 * use the same transport; therefore, op is not needed in this check. */
static inline int
shmem_shr_transport_use_atomic(shmem_ctx_t ctx, void *target, size_t len,
                               int pe, shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    return -1 != shmem_internal_get_shr_rank(pe);
#else
    return 0;
#endif
}


static inline void
shmem_shr_transport_put_scalar(shmem_ctx_t ctx, void *target,
                               const void *source, size_t len, int pe)
{
#if USE_MEMCPY
    memcpy(target, source, len);
#elif USE_XPMEM
    shmem_transport_xpmem_put(target, source, len, pe,
                              shmem_internal_get_shr_rank(pe));
#elif USE_CMA
    shmem_transport_cma_put(target, source, len, pe,
                            shmem_internal_get_shr_rank(pe));

#elif USE_MMAP
    shmem_transport_mmap_put(target, source, len, pe,
                             shmem_internal_get_shr_rank(pe));
#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline void
shmem_shr_transport_put(shmem_ctx_t ctx, void *target, const void *source,
                        size_t len, int pe)
{
#if USE_MEMCPY
    memcpy(target, source, len);
#elif USE_XPMEM
    shmem_transport_xpmem_put(target, source, len, pe,
                              shmem_internal_get_shr_rank(pe));
#elif USE_CMA
    shmem_transport_cma_put(target, source, len, pe,
                            shmem_internal_get_shr_rank(pe));

#elif USE_MMAP
    shmem_transport_mmap_put(target, source, len, pe,
                             shmem_internal_get_shr_rank(pe));
#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline void
shmem_shr_transport_get(shmem_ctx_t ctx, void *target, const void *source,
                        size_t len, int pe)
{
#if USE_MEMCPY
    memcpy(target, source, len);
#elif USE_XPMEM
    shmem_transport_xpmem_get(target, source, len, pe,
                              shmem_internal_get_shr_rank(pe));
#elif USE_CMA
    shmem_transport_cma_get(target, source, len, pe,
                            shmem_internal_get_shr_rank(pe));

#elif USE_MMAP
    shmem_transport_mmap_get(target, source, len, pe,
                             shmem_internal_get_shr_rank(pe));
#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline void
shmem_shr_transport_swap(shmem_ctx_t ctx, void *target, void *source,
                         void *dest, size_t len, int pe,
                         shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    int noderank = shmem_internal_get_shr_rank(pe);
    void *remote_ptr;

    if (noderank == -1)
        RAISE_ERROR_MSG("No shared memory path to peer %d\n", pe);

    shmem_shr_transport_ptr(target, noderank, &remote_ptr);

#define SHMEM_DEF_SWAP(STYPE,TYPE,ITYPE)                                \
        case ITYPE:                                                     \
                __atomic_exchange((TYPE *)remote_ptr, (TYPE *)source,   \
                                  (TYPE *)dest, __ATOMIC_ACQ_REL);      \
            break;

    switch (datatype) {
SHMEM_DEFINE_FOR_EXTENDED_AMO(SHMEM_DEF_SWAP)
        default:
            RAISE_ERROR_MSG("Unsupported datatype dtype=%d\n", datatype);
    }
#undef SHMEM_DEF_SWAP

#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline
void
shmem_shr_transport_cswap(shmem_ctx_t ctx, void *target, void *source,
                          void *dest, void *operand, size_t len,
                          int pe, shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    int noderank = shmem_internal_get_shr_rank(pe);
    void *remote_ptr;

    if (noderank == -1)
        RAISE_ERROR_MSG("No shared memory path to peer %d\n", pe);

    shmem_shr_transport_ptr(target, noderank, &remote_ptr);

#define SHMEM_DEF_CSWAP(STYPE,TYPE,ITYPE)                                       \
        case ITYPE:                                                             \
            {                                                                   \
                TYPE expected = *(TYPE *)operand;                               \
                bool swapped = __atomic_compare_exchange((TYPE *)remote_ptr,    \
                                                         &expected,             \
                                                         (TYPE *)source,        \
                                                         false,                 \
                                                         __ATOMIC_ACQ_REL,      \
                                                         __ATOMIC_ACQUIRE);     \
                if (swapped)                                                    \
                    *(TYPE *)dest = *(TYPE *)operand;                           \
                else                                                            \
                    /* expected contains the value of remote_ptr */             \
                    *(TYPE *)dest = expected;                                   \
            }                                                                   \
            break;

    switch (datatype) {
SHMEM_DEFINE_FOR_AMO(SHMEM_DEF_CSWAP)
        default:
            RAISE_ERROR_MSG("Unsupported datatype dtype=%d\n", datatype);
    }
#undef SHMEM_DEF_CSWAP

#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline
void
shmem_shr_transport_mswap(shmem_ctx_t ctx, void *target, void *source,
                          void *dest, void *mask, size_t len,
                          int pe, shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    int noderank = shmem_internal_get_shr_rank(pe);
    void *remote_ptr;
    bool done = false;

    if (noderank == -1)
        RAISE_ERROR_MSG("No shared memory path to peer %d\n", pe);

    shmem_shr_transport_ptr(target, noderank, &remote_ptr);

    switch (datatype) {
        case SHM_INTERNAL_INT:
            while (!done) {
                int v = __atomic_load_n((int *)remote_ptr, __ATOMIC_ACQUIRE);

                int new = ((unsigned int) v & ~*(unsigned int *)mask) |
                          (*(unsigned int *)source & *(unsigned int *)mask);

                done = __atomic_compare_exchange((int *)remote_ptr,
                                                 &v,
                                                 &new,
                                                 false,
                                                 __ATOMIC_ACQ_REL,
                                                 __ATOMIC_ACQUIRE);
                *(int *)dest = v;
            }
            break;
        default:
            RAISE_ERROR_MSG("Unsupported datatype dtype=%d\n", datatype);
    }
#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline
void
shmem_shr_transport_atomic(shmem_ctx_t ctx, void *target, const void *source,
                           size_t len, int pe, shm_internal_op_t op,
                           shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    int noderank = shmem_internal_get_shr_rank(pe);
    void *remote_ptr;

    if (noderank == -1)
        RAISE_ERROR_MSG("No shared memory path to peer %d\n", pe);

    shmem_shr_transport_ptr(target, noderank, &remote_ptr);

#define SHMEM_DEF_BAND_OP(STYPE,TYPE,ITYPE)                                                     \
                case ITYPE:                                                                     \
                    __atomic_fetch_and((TYPE *)remote_ptr, *((TYPE *)source), __ATOMIC_RELEASE);\
                    break;

#define SHMEM_DEF_BOR_OP(STYPE,TYPE,ITYPE)                                                      \
                case ITYPE:                                                                     \
                    __atomic_fetch_or((TYPE *)remote_ptr, *((TYPE *)source), __ATOMIC_RELEASE); \
                    break;

#define SHMEM_DEF_BXOR_OP(STYPE,TYPE,ITYPE)                                                     \
                case ITYPE:                                                                     \
                    __atomic_fetch_xor((TYPE *)remote_ptr, *((TYPE *)source), __ATOMIC_RELEASE);\
                    break;

#define SHMEM_DEF_SUM_OP(STYPE,TYPE,ITYPE)                                                      \
                case ITYPE:                                                                     \
                    __atomic_fetch_add((TYPE *)remote_ptr, *((TYPE *)source), __ATOMIC_RELEASE);\
                    break;

    switch (op) {
        case SHM_INTERNAL_BAND:
            switch(datatype) {
SHMEM_DEFINE_FOR_BITWISE_AMO(SHMEM_DEF_BAND_OP)
                default:
                    RAISE_ERROR_MSG("Unsupported datatype op=%d, dtype=%d\n", op, datatype);
            }
            break;
        case SHM_INTERNAL_BOR:
            switch(datatype) {
SHMEM_DEFINE_FOR_BITWISE_AMO(SHMEM_DEF_BOR_OP)
                default:
                    RAISE_ERROR_MSG("Unsupported datatype op=%d, dtype=%d\n", op, datatype);
            }
            break;
        case SHM_INTERNAL_BXOR:
            switch(datatype) {
SHMEM_DEFINE_FOR_BITWISE_AMO(SHMEM_DEF_BXOR_OP)
                default:
                    RAISE_ERROR_MSG("Unsupported datatype op=%d, dtype=%d\n", op, datatype);
            }
            break;
        case SHM_INTERNAL_SUM:
            switch(datatype) {
SHMEM_DEFINE_FOR_AMO(SHMEM_DEF_SUM_OP)
                default:
                    RAISE_ERROR_MSG("Unsupported datatype op=%d, dtype=%d\n", op, datatype);
            }
            break;
        /* Note: The following ops are only used by AMO reductions, which are
         * presently disabled when shared memory AMOs are enabled. */
        case SHM_INTERNAL_PROD:
        case SHM_INTERNAL_MIN:
        case SHM_INTERNAL_MAX:
        default:
            RAISE_ERROR_MSG("Unsupported op op=%d, dtype=%d\n", op, datatype);
    }

#undef SHMEM_DEF_BAND_OP
#undef SHMEM_DEF_BOR_OP
#undef SHMEM_DEF_BXOR_OP
#undef SHMEM_DEF_SUM_OP

#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline
void
shmem_shr_transport_atomic_fetch(shmem_ctx_t ctx, void *target,
                                 const void *source, size_t len,
                                 int pe, shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    int noderank = shmem_internal_get_shr_rank(pe);
    void *remote_ptr;

    if (noderank == -1)
        RAISE_ERROR_MSG("No shared memory path to peer %d\n", pe);

    shmem_shr_transport_ptr((void *)source, noderank, &remote_ptr);

#define SHMEM_DEF_FETCH(STYPE,TYPE,ITYPE)                                       \
        case ITYPE:                                                             \
            __atomic_load((TYPE *)remote_ptr, (TYPE *)target, __ATOMIC_ACQUIRE);\
            break;

    switch (datatype) {
SHMEM_DEFINE_FOR_EXTENDED_AMO(SHMEM_DEF_FETCH)
        default:
            RAISE_ERROR_MSG("Unsupported datatype dtype=%d\n", datatype);
    }
#undef SHMEM_DEF_FETCH

#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline
void
shmem_shr_transport_atomic_set(shmem_ctx_t ctx, void *target,
                               const void *source, size_t len,
                               int pe, shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    int noderank = shmem_internal_get_shr_rank(pe);
    void *remote_ptr;

    if (noderank == -1)
        RAISE_ERROR_MSG("No shared memory path to peer %d\n", pe);

    shmem_shr_transport_ptr(target, noderank, &remote_ptr);

#define SHMEM_DEF_SET(STYPE,TYPE,ITYPE)                                                 \
        case ITYPE:                                                                     \
            __atomic_store((TYPE *)remote_ptr, (TYPE *)source, __ATOMIC_RELEASE);       \
            break;

    switch (datatype) {
SHMEM_DEFINE_FOR_EXTENDED_AMO(SHMEM_DEF_SET)
        default:
            RAISE_ERROR_MSG("Unsupported datatype dtype=%d\n", datatype);
    }
#undef SHMEM_DEF_SET

#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline
void
shmem_shr_transport_atomicv(shmem_ctx_t ctx, void *target, const void *source,
                            size_t len, int pe, shm_internal_op_t op,
                            shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    RAISE_ERROR_STR("No path to peer");
#else
    RAISE_ERROR_STR("No path to peer");
#endif
}



static inline void
shmem_shr_transport_fetch_atomic(shmem_ctx_t ctx, void *target, void *source,
                                 void *dest, size_t len, int pe,
                                 shm_internal_op_t op,
                                 shm_internal_datatype_t datatype)
{
#if USE_SHR_ATOMICS
    int noderank = shmem_internal_get_shr_rank(pe);
    void *remote_ptr;

    if (noderank == -1)
        RAISE_ERROR_MSG("No shared memory path to peer %d\n", pe);

    shmem_shr_transport_ptr(target, noderank, &remote_ptr);

#define SHMEM_DEF_BAND_OP(STYPE,TYPE,ITYPE)                                                     \
                case ITYPE:                                                                     \
                    *(TYPE *)dest = __atomic_fetch_and((TYPE *)remote_ptr, *((TYPE *)source),   \
                                                       __ATOMIC_ACQ_REL);                       \
                    break;

#define SHMEM_DEF_BOR_OP(STYPE,TYPE,ITYPE)                                                      \
                case ITYPE:                                                                     \
                    *(TYPE *)dest = __atomic_fetch_or((TYPE *)remote_ptr, *((TYPE *)source),    \
                                                      __ATOMIC_ACQ_REL);                        \
                    break;

#define SHMEM_DEF_BXOR_OP(STYPE,TYPE,ITYPE)                                                     \
                case ITYPE:                                                                     \
                    *(TYPE *)dest = __atomic_fetch_xor((TYPE *)remote_ptr, *((TYPE *)source),   \
                                                       __ATOMIC_ACQ_REL);                       \
                    break;

#define SHMEM_DEF_SUM_OP(STYPE,TYPE,ITYPE)                                                      \
                case ITYPE:                                                                     \
                    *(TYPE *)dest = __atomic_fetch_add((TYPE *)remote_ptr, *((TYPE *)source),   \
                                                       __ATOMIC_ACQ_REL);                       \
                    break;

    switch (op) {
        case SHM_INTERNAL_BAND:
            switch(datatype) {
SHMEM_DEFINE_FOR_BITWISE_AMO(SHMEM_DEF_BAND_OP)
                default:
                    RAISE_ERROR_MSG("Unsupported datatype op=%d, dtype=%d\n", op, datatype);
            }
            break;
        case SHM_INTERNAL_BOR:
            switch(datatype) {
SHMEM_DEFINE_FOR_BITWISE_AMO(SHMEM_DEF_BOR_OP)
                default:
                    RAISE_ERROR_MSG("Unsupported datatype op=%d, dtype=%d\n", op, datatype);
            }
            break;
        case SHM_INTERNAL_BXOR:
            switch(datatype) {
SHMEM_DEFINE_FOR_BITWISE_AMO(SHMEM_DEF_BXOR_OP)
                default:
                    RAISE_ERROR_MSG("Unsupported datatype op=%d, dtype=%d\n", op, datatype);
            }
            break;
        case SHM_INTERNAL_SUM:
            switch(datatype) {
SHMEM_DEFINE_FOR_AMO(SHMEM_DEF_SUM_OP)
                default:
                    RAISE_ERROR_MSG("Unsupported datatype op=%d, dtype=%d\n", op, datatype);
            }
            break;
        /* Note: The following ops are only used by AMO reductions, which are
         * presently disabled when shared memory AMOs are enabled. */
        case SHM_INTERNAL_PROD:
        case SHM_INTERNAL_MIN:
        case SHM_INTERNAL_MAX:
        default:
            RAISE_ERROR_MSG("Unsupported op op=%d, dtype=%d\n", op, datatype);
    }

#undef SHMEM_DEF_BAND_OP
#undef SHMEM_DEF_BOR_OP
#undef SHMEM_DEF_BXOR_OP
#undef SHMEM_DEF_SUM_OP

#else
    RAISE_ERROR_STR("No path to peer");
#endif
}


static inline void
shmem_shr_transport_put_signal(shmem_ctx_t ctx, void *target,
                               const void *source, size_t len,
                               uint64_t *sig_addr, uint64_t signal, int sig_op, int pe)
{
#if USE_MEMCPY
    memcpy(target, source, len);
    if (sig_op == SHMEM_SIGNAL_ADD) *sig_addr += signal;
    else *sig_addr = signal;
#elif USE_XPMEM
    shmem_transport_xpmem_put(target, source, len, pe,
                              shmem_internal_get_shr_rank(pe));
    shmem_internal_membar_acq_rel(); /* Memory fence to ensure target PE observes
                                        stores in the correct order */
#elif USE_MMAP
    shmem_transport_mmap_put(target, source, len, pe,
                              shmem_internal_get_shr_rank(pe));
    shmem_internal_membar_acq_rel(); /* Memory fence to ensure target PE observes
                                        stores in the correct order */

#if USE_SHR_ATOMICS 
    if (sig_op == SHMEM_SIGNAL_ADD)
        shmem_shr_transport_atomic(ctx, sig_addr, &signal, sizeof(uint64_t),
                                   pe, SHM_INTERNAL_SUM, SHM_INTERNAL_UINT64);
    else
        shmem_shr_transport_atomic_set(ctx, sig_addr, &signal, sizeof(uint64_t),
                                       pe, SHM_INTERNAL_UINT64);
#else
    if (sig_op == SHMEM_SIGNAL_ADD)
        shmem_transport_atomic((shmem_transport_ctx_t *) ctx, sig_addr, &signal, sizeof(uint64_t),
                               pe, SHM_INTERNAL_SUM, SHM_INTERNAL_UINT64);
    else
        shmem_transport_atomic_set((shmem_transport_ctx_t *) ctx, sig_addr, &signal,
                                   sizeof(uint64_t), pe, SHM_INTERNAL_UINT64);
#endif
#elif USE_CMA
    shmem_transport_cma_put(target, source, len, pe,
                            shmem_internal_get_shr_rank(pe));
    shmem_internal_membar_acq_rel(); /* Memory fence to ensure target PE observes
                                        stores in the correct order */
    /* Using network atomics as CMA does not support atomic operations */
    if (sig_op == SHMEM_SIGNAL_ADD)
        shmem_transport_atomic((shmem_transport_ctx_t *) ctx, sig_addr, &signal, sizeof(uint64_t),
                               pe, SHM_INTERNAL_SUM, SHM_INTERNAL_UINT64);
    else
        shmem_transport_atomic_set((shmem_transport_ctx_t *) ctx, sig_addr, &signal,
                                   sizeof(uint64_t), pe, SHM_INTERNAL_UINT64);
#else
    RAISE_ERROR_STR("No path to peer");
#endif
}

#endif /* SHR_TRANSPORT_H */
