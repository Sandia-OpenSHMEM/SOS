.TH SHMEM_CTX_DESTROY 3 "Open Source Software Solutions, Inc." "OpenSHMEM Library Documentation"
./ sectionStart
.SH NAME
shmem_ctx_destroy \- 
Destroy a communication context.

./ sectionEnd


./ sectionStart
.SH   SYNOPSIS
./ sectionEnd

./ sectionStart
.SS C/C++:

.B void
.B shmem\_ctx\_destroy(shmem_ctx_t
.I ctx
.B );



./ sectionEnd




./ sectionStart

.SH DESCRIPTION
.SS Arguments
.BR "IN " -
.I ctx
- Handle to the context that will be destroyed.
./ sectionEnd


./ sectionStart

.SS API Description

.B shmem\_ctx\_destroy
destroys a context that was created by a call to
.B shmem\_ctx\_create
or 
.BR "shmem\_team\_create\_ctx" .
It is the user's responsibility to ensure that
the context is not used after it has been destroyed, for example when the
destroyed context is used by multiple threads. This function
performs an implicit quiet operation on the given context before it is freed.
If 
.I ctx
has the value SHMEM\_CTX\_INVALID, no operation is
performed.

./ sectionEnd


./ sectionStart

.SS Return Values

None.

./ sectionEnd


./ sectionStart

.SS API Notes

Destroying a context makes it impossible for the user to complete
communication operations that are pending on that context. This includes
nonblocking communication operations, whose local buffers are only returned
to the user after the operations have been completed. An implicit quiet is
performed when freeing a context to avoid this ambiguity.

A context with the SHMEM\_CTX\_PRIVATE option enabled must be
destroyed by the thread that created it.

./ sectionEnd



./ sectionStart
.SS Examples



The following example demonstrates the use of contexts in a multithreaded
C11 program that uses OpenMP for threading. This example shows the
shared counter load balancing method and illustrates the use of contexts
for thread isolation.

.nf
#include <shmem.h>
#include <stdio.h>

long pwrk[SHMEM_REDUCE_MIN_WRKDATA_SIZE];
long psync[SHMEM_REDUCE_SYNC_SIZE];

long task_cntr = 0;  /* Next task counter */
long tasks_done = 0; /* Tasks done by this PE */
long total_done = 0; /* Total tasks done by all PEs */

int main(void) {
 int tl, i;
 long ntasks = 1024; /* Total tasks per PE */

 for (i = 0; i < SHMEM_REDUCE_SYNC_SIZE; i++)
   psync[i] = SHMEM_SYNC_VALUE;

 shmem_init_thread(SHMEM_THREAD_MULTIPLE, &tl);
 if (tl != SHMEM_THREAD_MULTIPLE)
   shmem_global_exit(1);

 int mype = shmem_my_pe();
 int npes = shmem_n_pes();

#pragma omp parallel reduction(+ : tasks_done)
 {
   shmem_ctx_t ctx;
   int task_pe = mype, pes_done = 0;
   int ret = shmem_ctx_create(SHMEM_CTX_PRIVATE, &ctx);

   if (ret != 0) {
     printf("%d: Error creating context (%d)\\n", mype, ret);
     shmem_global_exit(2);
   }

   /* Process tasks on all PEs, starting with the local PE.  After
    * all tasks on a PE are completed, help the next PE. */
   while (pes_done < npes) {
     long task = shmem_atomic_fetch_inc(ctx, &task_cntr, task_pe);
     while (task < ntasks) {
       /* Perform task (task_pe, task) */
       tasks_done++;
       task = shmem_atomic_fetch_inc(ctx, &task_cntr, task_pe);
     }
     pes_done++;
     task_pe = (task_pe + 1) % npes;
   }

   shmem_ctx_destroy(ctx);
 }

 shmem_long_sum_to_all(&total_done, &tasks_done, 1, 0, 0, npes, pwrk, psync);

 int result = (total_done != ntasks * npes);
 shmem_finalize();
 return result;
}
.fi



The following example demonstrates the use of contexts in a
single-threaded C11 program that performs a summation reduction where
the data contained in the 
.I in\_buf
arrays on all PEs is reduced into
the 
.I out\_buf
arrays on all PEs. The buffers are divided into
segments and processing of the segments is pipelined. Contexts are used
to overlap an all-to-all exchange of data for segment 
.I p
with the
local reduction of segment 
.IR "p-1" .


.nf
#include <shmem.h>
#include <stdio.h>
#include <stdlib.h>

#define LEN 8192 /* Full buffer length */
#define PLEN 512 /* Length of each pipeline stage */

int in_buf[LEN], out_buf[LEN];

int main(void) {
 int i, j, *pbuf[2];
 shmem_ctx_t ctx[2];

 shmem_init();
 int mype = shmem_my_pe();
 int npes = shmem_n_pes();

 pbuf[0] = shmem_malloc(PLEN * npes * sizeof(int));
 pbuf[1] = shmem_malloc(PLEN * npes * sizeof(int));

 int ret_0 = shmem_ctx_create(0, &ctx[0]);
 int ret_1 = shmem_ctx_create(0, &ctx[1]);
 if (ret_0 || ret_1)
   shmem_global_exit(1);

 for (i = 0; i < LEN; i++) {
   in_buf[i] = mype;
   out_buf[i] = 0;
 }

 int p_idx = 0, p = 0; /* Index of ctx and pbuf (p_idx) for cur. pipeline stage (p) */
 for (i = 1; i <= npes; i++)
   shmem_put_nbi(ctx[p_idx], &pbuf[p_idx][PLEN * mype], &in_buf[PLEN * p], PLEN,
                 (mype + i) % npes);

 /* Issue puts for pipeline stage p, then accumulate results for stage p-1 */
 for (p = 1; p < LEN / PLEN; p++) {
   p_idx ^= 1;
   for (i = 1; i <= npes; i++)
     shmem_put_nbi(ctx[p_idx], &pbuf[p_idx][PLEN * mype], &in_buf[PLEN * p], PLEN,
                   (mype + i) % npes);

   shmem_ctx_quiet(ctx[p_idx ^ 1]);
   shmem_sync_all();
   for (i = 0; i < npes; i++)
     for (j = 0; j < PLEN; j++)
       out_buf[PLEN * (p - 1) + j] += pbuf[p_idx ^ 1][PLEN * i + j];
 }

 shmem_ctx_quiet(ctx[p_idx]);
 shmem_sync_all();
 for (i = 0; i < npes; i++)
   for (j = 0; j < PLEN; j++)
     out_buf[PLEN * (p - 1) + j] += pbuf[p_idx][PLEN * i + j];

 shmem_finalize();
 return 0;
}
.fi



The following example demonstrates the use of SHMEM\_CTX\_INVALID
in a C11 program that uses thread-local storage to provide each
thread an implicit context handle via a ``library'' put routine without
explicit management of the context handle from ``user'' code.

.nf
#include <omp.h>
#include <shmem.h>
#include <stddef.h>

_Thread_local shmem_ctx_t thread_ctx = SHMEM_CTX_INVALID;

void lib_thread_register(void) {
 if (thread_ctx == SHMEM_CTX_INVALID)
   if (shmem_ctx_create(SHMEM_CTX_PRIVATE, &thread_ctx) && shmem_ctx_create(0, &thread_ctx))
     thread_ctx = SHMEM_CTX_DEFAULT;
}

void lib_thread_unregister(void) {
 if (thread_ctx != SHMEM_CTX_DEFAULT) {
   shmem_ctx_destroy(thread_ctx);
   thread_ctx = SHMEM_CTX_INVALID;
 }
}

void lib_thread_putmem(void *dst, const void *src, size_t nbytes, int pe) {
 shmem_ctx_putmem(thread_ctx, dst, src, nbytes, pe);
}

int main() {
 int provided;
 if (shmem_init_thread(SHMEM_THREAD_MULTIPLE, &provided))
   return 1;
 if (provided != SHMEM_THREAD_MULTIPLE)
   shmem_global_exit(2);

 const int mype = shmem_my_pe();
 const int npes = shmem_n_pes();
 const int count = 1 << 15;

 int *src_bufs[npes];
 int *dst_bufs[npes];
 for (int i = 0; i < npes; i++) {
   src_bufs[i] = shmem_calloc(count, sizeof(*src_bufs[i]));
   if (src_bufs[i] == NULL)
     shmem_global_exit(3);
   dst_bufs[i] = shmem_calloc(count, sizeof(*dst_bufs[i]));
   if (dst_bufs[i] == NULL)
     shmem_global_exit(4);
 }

#pragma omp parallel
 {
   int my_thrd = omp_get_thread_num();
#pragma omp for
   for (int i = 0; i < npes; i++)
     for (int j = 0; j < count; j++)
       src_bufs[i][j] = (mype << 10) + my_thrd;

   lib_thread_register();

#pragma omp for
   for (int i = 0; i < npes; i++)
     lib_thread_putmem(dst_bufs[mype], src_bufs[i], count * sizeof(*src_bufs[i]), i);

   lib_thread_unregister();
 }

 shmem_finalize();
 return 0;
}
.fi






